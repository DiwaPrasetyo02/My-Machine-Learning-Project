{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "def8e46c-7606-4991-9b29-9223ccacd54b",
      "metadata": {
        "id": "def8e46c-7606-4991-9b29-9223ccacd54b"
      },
      "source": [
        "# Project: Deep Learning - Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b68327-fc7b-43de-9f16-b058d11d775b",
      "metadata": {
        "id": "e0b68327-fc7b-43de-9f16-b058d11d775b"
      },
      "source": [
        "## Project Structure\n",
        "\n",
        "Your project should be organized into five main sections."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ecc459-5019-42d8-84a6-8644cecafef3",
      "metadata": {
        "id": "25ecc459-5019-42d8-84a6-8644cecafef3"
      },
      "source": [
        "### 1. Package and Module Installation\n",
        "\n",
        "First, let's pool all package and module that you'll need in the installation section below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62606ca1-5868-4c65-93ef-1d6ee8d8d59a",
      "metadata": {
        "id": "62606ca1-5868-4c65-93ef-1d6ee8d8d59a"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio torchtext scikit-learn pandas numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCWmfDSF0_ZY",
        "outputId": "364c4b2c-11a3-4d59-aff0-94fe0c767bad"
      },
      "id": "iCWmfDSF0_ZY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0837717-de95-4193-9898-e2f4cadfcfc6",
      "metadata": {
        "id": "b0837717-de95-4193-9898-e2f4cadfcfc6"
      },
      "source": [
        "### 2. Data Loading and Preprocessing\n",
        "\n",
        "Load the chosen dataset and preprocess it for deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0e5e58-277e-41ef-9b1c-951e5d150191",
      "metadata": {
        "id": "3b0e5e58-277e-41ef-9b1c-951e5d150191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c761b796-4b94-4673-f1b2-6b7f82977fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenization\n",
        "def tokenizer(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['label', 'text']\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ce0c59-0e94-480a-81ae-528e68356a15",
      "metadata": {
        "id": "30ce0c59-0e94-480a-81ae-528e68356a15"
      },
      "source": [
        "### 3. Model Building\n",
        "\n",
        "Define your deep learning model's architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a",
      "metadata": {
        "id": "1aa3c3f7-c6c5-4419-9b25-e8d7a8ec345a"
      },
      "outputs": [],
      "source": [
        "# Write your code here for Model Building here\n",
        "import torch.nn as nn\n",
        "\n",
        "class SpamClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "        super(SpamClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, _ = self.rnn(embedded)\n",
        "        final_feature_map = rnn_out[:, -1, :]  # get the output of the last time step\n",
        "        out = self.fc(final_feature_map)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = len(vocab) + 1\n",
        "embed_dim = 256\n",
        "hidden_dim = 128\n",
        "output_dim = 2\n",
        "\n",
        "model = SpamClassifier(vocab_size, embed_dim, hidden_dim, output_dim)\n",
        "\n",
        "# define your Deep Learning Model here, training is in the next section.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585b925f-fcf0-4518-81d8-598dba65d646",
      "metadata": {
        "id": "585b925f-fcf0-4518-81d8-598dba65d646"
      },
      "source": [
        "### 4. Model Training\n",
        "\n",
        "Train your model and evaluate its performance using validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee33d9bc-2b35-4f78-b5d8-3eb65db1e361",
      "metadata": {
        "id": "ee33d9bc-2b35-4f78-b5d8-3eb65db1e361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cff0fc-df52-4ecb-f78a-e2e2166b1d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3927784115076065\n",
            "Epoch 2, Loss: 0.16077557663832392\n",
            "Epoch 3, Loss: 0.08840025863277592\n",
            "Epoch 4, Loss: 0.04481233745713585\n",
            "Epoch 5, Loss: 0.030548392448274952\n"
          ]
        }
      ],
      "source": [
        "# Write your code here for Model Training here\n",
        "\n",
        "\n",
        "#define the iteration\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "def train(model, train_loader, optimizer, loss_fn, num_epochs=20):\n",
        "    model.train()\n",
        "    global dl_loss_value  # Declare the global variable for the loss value\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for texts, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(texts)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        dl_loss_value = total_loss / len(train_loader)  # Store the loss value in dl_loss_value\n",
        "        print(f'Epoch {epoch + 1}, Loss: {dl_loss_value}')\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, optimizer, loss_fn, num_epochs=5)\n",
        "\n",
        "\n",
        "#create the training loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d391ec9-ca95-4c56-b4f6-fccf8e0be14a",
      "metadata": {
        "id": "1d391ec9-ca95-4c56-b4f6-fccf8e0be14a"
      },
      "source": [
        "### 5. Model Evaluation\n",
        "Evaluate your model's performance on the test data using the grading scheme defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ca8f78-e33c-4552-9f4d-8bed711e661f",
      "metadata": {
        "id": "c8ca8f78-e33c-4552-9f4d-8bed711e661f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243e53ff-0eab-46d2-ced2-5d11778d287b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.13%\n"
          ]
        }
      ],
      "source": [
        "# Write your code here for Model Evaluation here\n",
        "\n",
        "\n",
        "#define the iteration\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluation function with dl_accuracy\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    global dl_accuracy  # Declare the global variable for accuracy\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in test_loader:\n",
        "            outputs = model(texts)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    dl_accuracy = accuracy_score(all_labels, all_preds) * 100  # Store accuracy in dl_accuracy\n",
        "    print(f'Test Accuracy: {dl_accuracy:.2f}%')\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate(model, test_loader)\n",
        "\n",
        "#create the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010d7f7f-711d-4f41-82a3-3c2562e59709",
      "metadata": {
        "id": "010d7f7f-711d-4f41-82a3-3c2562e59709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4595e41b-aded-461b-f1d8-f17433d03d8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Assignment successfully submitted'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Submit Method\n",
        "\n",
        "# Do not change the code below\n",
        "question_id = \"01_dl_project_accuracy\"\n",
        "submit(student_id, name, assignment_id, str(dl_accuracy), question_id, drive_link)\n",
        "question_id = \"02_dl_project_loss_value\"\n",
        "submit(student_id, name, assignment_id, str(dl_loss_value), question_id, drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa89b9ff-0d31-416a-b3c4-851c725fadf7",
      "metadata": {
        "id": "aa89b9ff-0d31-416a-b3c4-851c725fadf7"
      },
      "source": [
        "## FIN"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}